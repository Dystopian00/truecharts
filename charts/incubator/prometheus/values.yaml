image:
  repository: grafana/loki
  pullPolicy: IfNotPresent
  tag: 2.4.1@sha256:f53b40251a601e491c36a4153aa65630c4ebf59404f36d6a532fb261a576ea9f

controller:
  enabled: false

service:
  main:
    enabled: false
    ports:
      main:
        enabled: false

probes:
  liveness:
    enabled: false

  readiness:
    enabled: false

  startup:
    enabled: false

prometheus-stack:
  enabled: true
  ## Create default rules for monitoring the cluster
  ##
  defaultRules:
    create: true
    rules:
      alertmanager: true
      etcd: true
      general: true
      k8s: true
      kubeApiserver: true
      kubeApiserverAvailability: true
      kubeApiserverError: true
      kubeApiserverSlos: true
      kubelet: true
      kubePrometheusGeneral: true
      kubePrometheusNodeAlerting: true
      kubePrometheusNodeRecording: true
      kubernetesAbsent: true
      kubernetesApps: true
      kubernetesResources: true
      kubernetesStorage: true
      kubernetesSystem: true
      kubeScheduler: true
      kubeStateMetrics: true
      network: true
      node: true
      prometheus: true
      prometheusOperator: true
      time: true

    ## Runbook url prefix for default rules
    runbookUrl: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#

  alertmanager:
    ## Do not deploy alertmanager
    enabled: false

  ## Using default values from https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml
  ##
  grafana:
    enabled: false

  ## Component scraping the kube api server
  ##
  kubeApiServer:
    enabled: true

  ## Component scraping the kubelet and kubelet-hosted cAdvisor
  ##
  kubelet:
    enabled: true

## Component scraping the kube controller manager
  ##
  kubeControllerManager:
    enabled: false

  ## Component scraping coreDns. Use either this or kubeDns
  ##
  coreDns:
    enabled: true

  ## Component scraping etcd
  ##
  kubeEtcd:
    enabled: false

  ## Component scraping kube scheduler
  ##
  kubeScheduler:
    enabled: false

  ## Component scraping kube proxy
  ##
  kubeProxy:
    enabled: false

  ## Manages Prometheus and Alertmanager components
  ##
  prometheusOperator:
    enabled: true

  ## Deploy a Prometheus instance
  ##
  prometheus:
    enabled: true

    # Service for thanos service discovery on sidecar
    # Enable this can make Thanos Query can use
    # `--store=dnssrv+_grpc._tcp.${kube-prometheus-stack.fullname}-thanos-discovery.${namespace}.svc.cluster.local` to discovery
    # Thanos sidecar on prometheus nodes
    # (Please remember to change ${kube-prometheus-stack.fullname} and ${namespace}. Not just copy and paste!)
    thanosService:
      enabled: false

    # ServiceMonitor to scrape Sidecar metrics
    # Needs thanosService to be enabled as well
    thanosServiceMonitor:
      enabled: false

    # Service for external access to sidecar
    # Enabling this creates a service to expose thanos-sidecar outside the cluster.
    thanosServiceExternal:
      enabled: false

    ## Configuration for Prometheus service
    ##
    service:
      ## Port for Prometheus Service to listen on
      ##
      port: 9090

      ## To be used with a proxy extraContainer port
      targetPort: 9090

      ## List of IP addresses at which the Prometheus server service is available
      ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips
      ##
      externalIPs: []

      ## Port to expose on each node
      ## Only used if service.type is 'NodePort'
      ##
      nodePort: 30090

      ## Loadbalancer IP
      ## Only use if service.type is "LoadBalancer"
      loadBalancerIP: ""
      loadBalancerSourceRanges: []
      ## Service type
      ##
      type: ClusterIP

    ## Configuration for creating a separate Service for each statefulset Prometheus replica
    ##
    servicePerReplica:
      enabled: false

    # Ingress exposes thanos sidecar outside the cluster
    thanosIngress:
      enabled: false


    ingress:
      enabled: false

    ## Settings affecting prometheusSpec
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
    ##
    prometheusSpec:
      ## If true, pass --storage.tsdb.max-block-duration=2h to prometheus. This is already done if using Thanos
      ##
      disableCompaction: false
      ## APIServerConfig
      ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#apiserverconfig
      ##
      apiserverConfig: {}

      ## Interval between consecutive scrapes.
      ## Defaults to 30s.
      ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/release-0.44/pkg/prometheus/promcfg.go#L180-L183
      ##
      scrapeInterval: ""

      ## Number of seconds to wait for target to respond before erroring
      ##
      scrapeTimeout: ""

      ## Interval between consecutive evaluations.
      ##
      evaluationInterval: ""

      ## ListenLocal makes the Prometheus server listen on loopback, so that it does not bind against the Pod IP.
      ##
      listenLocal: false

      ## EnableAdminAPI enables Prometheus the administrative HTTP API which includes functionality such as deleting time series.
      ## This is disabled by default.
      ## ref: https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-admin-apis
      ##
      enableAdminAPI: false

      # EnableFeatures API enables access to Prometheus disabled features.
      # ref: https://prometheus.io/docs/prometheus/latest/disabled_features/
      enableFeatures: []
      # - exemplar-storage

      ## Alertmanagers to which alerts will be sent
      ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#alertmanagerendpoints
      ##
      ## Default configuration will connect to the alertmanager deployed as part of this release
      ##
      alertingEndpoints: []
      # - name: ""
      #   namespace: ""
      #   port: http
      #   scheme: http
      #   pathPrefix: ""
      #   tlsConfig: {}
      #   bearerTokenFile: ""
      #   apiVersion: v2

      ## External URL at which Prometheus will be reachable.
      ##
      externalUrl: ""

      ## How long to retain metrics
      ##
      retention: 10d

      ## Maximum size of metrics
      ##
      retentionSize: ""

      ## Enable compression of the write-ahead log using Snappy.
      ##
      walCompression: false

      ## If true, the Operator won't process any Prometheus configuration changes
      ##
      paused: false

      ## Number of replicas of each shard to deploy for a Prometheus deployment.
      ## Number of replicas multiplied by shards is the total number of Pods created.
      ##
      replicas: 1

      ## EXPERIMENTAL: Number of shards to distribute targets onto.
      ## Number of replicas multiplied by shards is the total number of Pods created.
      ## Note that scaling down shards will not reshard data onto remaining instances, it must be manually moved.
      ## Increasing shards will not reshard data either but it will continue to be available from the same instances.
      ## To query globally use Thanos sidecar and Thanos querier or remote write data to a central location.
      ## Sharding is done on the content of the `__address__` target meta-label.
      ##
      shards: 1

      ## Log level for Prometheus be configured in
      ##
      logLevel: info

      ## Log format for Prometheus be configured in
      ##
      logFormat: logfmt

      ## Prefix used to register routes, overriding externalUrl route.
      ## Useful for proxies that rewrite URLs.
      ##
      routePrefix: /

      ## The remote_read spec configuration for Prometheus.
      ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#remotereadspec
      remoteRead: []
      # - url: http://remote1/read
      ## additionalRemoteRead is appended to remoteRead
      additionalRemoteRead: []

      ## Resource limits & requests
      ##
      resources: {}
      # requests:
      #   memory: 400Mi

      ## Prometheus StorageSpec for persistent data
      ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/user-guides/storage.md
      ##
      storageSpec: {}
      ## Using PersistentVolumeClaim
      ##
      #  volumeClaimTemplate:
      #    spec:
      #      storageClassName: gluster
      #      accessModes: ["ReadWriteOnce"]
      #      resources:
      #        requests:
      #          storage: 50Gi
      #    selector: {}

      ## Using tmpfs volume
      ##
      #  emptyDir:
      #    medium: Memory


      ## PortName to use for Prometheus.
      ##
      portName: "web"

      ## QueryLogFile specifies the file to which PromQL queries are logged. Note that this location must be writable,
      ## and can be persisted using an attached volume. Alternatively, the location can be set to a stdout location such
      ## as /dev/stdout to log querie information to the default Prometheus log stream. This is only available in versions
      ## of Prometheus >= 2.16.0. For more details, see the Prometheus docs (https://prometheus.io/docs/guides/query-log/)
      queryLogFile: false

      ## EnforcedSampleLimit defines global limit on number of scraped samples that will be accepted. This overrides any SampleLimit
      ## set per ServiceMonitor or/and PodMonitor. It is meant to be used by admins to enforce the SampleLimit to keep overall
      ## number of samples/series under the desired limit. Note that if SampleLimit is lower that value will be taken instead.
      enforcedSampleLimit: false

      ## EnforcedTargetLimit defines a global limit on the number of scraped targets. This overrides any TargetLimit set
      ## per ServiceMonitor or/and PodMonitor. It is meant to be used by admins to enforce the TargetLimit to keep the overall
      ## number of targets under the desired limit. Note that if TargetLimit is lower, that value will be taken instead, except
      ## if either value is zero, in which case the non-zero value will be used. If both values are zero, no limit is enforced.
      enforcedTargetLimit: false

      ## Per-scrape limit on number of labels that will be accepted for a sample. If more than this number of labels are present
      ## post metric-relabeling, the entire scrape will be treated as failed. 0 means no limit. Only valid in Prometheus versions
      ## 2.27.0 and newer.
      enforcedLabelLimit: false

      ## Per-scrape limit on length of labels name that will be accepted for a sample. If a label name is longer than this number
      ## post metric-relabeling, the entire scrape will be treated as failed. 0 means no limit. Only valid in Prometheus versions
      ## 2.27.0 and newer.
      enforcedLabelNameLengthLimit: false

      ## Per-scrape limit on length of labels value that will be accepted for a sample. If a label value is longer than this
      ## number post metric-relabeling, the entire scrape will be treated as failed. 0 means no limit. Only valid in Prometheus
      ## versions 2.27.0 and newer.
      enforcedLabelValueLengthLimit: false

      ## AllowOverlappingBlocks enables vertical compaction and vertical query merge in Prometheus. This is still experimental
      ## in Prometheus so it may change in any upcoming release.
      allowOverlappingBlocks: false
