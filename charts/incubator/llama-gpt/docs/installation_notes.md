# Installation notes

You can now run LlamaGPT with any of the following models depending upon your hardware:

| Model size | Model used                          | Minimum RAM required |
| ---------- | ----------------------------------- | -------------------- |
| 7B         | Nous Hermes Llama 2 7B (GGML q4_0)  | 8GB                  |
| 13B        | Nous Hermes Llama 2 13B (GGML q4_0) | 16GB                 |
| 70B        | Meta Llama 2 70B Chat (GGML q4_0)   | 48GB                 |
